{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How To Use The COSIMA Cookbook\n",
    "\n",
    "This notebook is designed to help new users get to grips with the COSIMA Cookbook. It assumes that:\n",
    " * You have access to the COSIMA cookbook.\n",
    " * We recommend using the latest version of the cookbook available through the `conda/analysis3-unstable` module on NCI.\n",
    " * You can fire up a Jupyter notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before starting,** load in some standard libraries that you are likely to need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import IPython.display\n",
    "import cmocean as cm\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, you **always** need to load the cosima_cookbook module. This provides a bunch of functions that you will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cosima_cookbook as cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Cookbook Philosophy\n",
    "The COSIMA Cookbook is a framework for analysing ocean-sea ice model output.\n",
    "It is designed to:\n",
    "* Provide examples of commonly used diagnostics;\n",
    "* Write efficient, well-documented, openly accessible code;\n",
    "* Encourage community input to the code;\n",
    "* Ensure diagnostic results are reproducible;\n",
    "* Process diagnostics directly from the model output, minimising creation of intermediate files;\n",
    "* Find methods to deal with the memory limitations of analysing high-resolution model output.\n",
    "\n",
    "\n",
    "### 1.1 A database of experiments\n",
    "The COSIMA Cookbook relies on a database of experiments in order to load model output. This database effectively holds metadata for each experiment, as well as variable names, data ranges and so on. \n",
    "\n",
    "There are two different ways for you to access the database:\n",
    "1. You can use the default database, which is periodically refreshed automatically. This database sits in `/g/data3/hh5/tmp/cosima/database/access-om2.db` and should be readable for all users. It includes all experiments stored in the COSIMA data directory under project `hh5` on NCI. The examples in this tutorial use this database.\n",
    "2. Otherwise, you can make your own database, which is stored in your own path and includes only the experiments you are interested in. Please refer to the `Make_Your_Own_Database` tutorial for instructions on how to create this database.\n",
    "\n",
    "To access the default database, you need to start a database session each time you fire up a notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = cc.database.create_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Inbuilt Database Functions\n",
    "\n",
    "We have constructed a few functions to help you operate the cookbook and to access the datasets. These functions all sit in the `cosima_cookbook` directory. For example, `netcdf_index.py` contains the above `build_index` function as well as a series of functions that are built to query the SQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_experiments` lists all of the experiments that are catalogued in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.querying.get_experiments(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, an experiment is a set of netCDF4 files as shown in the above table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_ncfiles` provides a list of all the netcdf filenames saved for a given experiment along with the time stamp for when that file was added to the cookbook database. Note that each of these filenames are present in some or all of the output directories -- **but the cookbook philosophy is that you don't need to know about the directories in which these files are stored**. To see the relevant files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.querying.get_ncfiles(session, '025deg_jra55v13_ryf8485_gmredi6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More usefully, `get_variables` provides a list of all the variables available in a specific experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.querying.get_variables(session, experiment='025deg_jra55v13_ryf8485_gmredi6', frequency='1 monthly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Omitting the `frequency` would give variables at all temporal frequencies.  To determine what frequencies are in a given experient, we can use `get_frequencies`. Leaving off the `experiment` gives all possible frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.querying.get_frequencies(session, experiment='025deg_jra55v13_ryf8485_gmredi6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Loading data from a netcdf file\n",
    "\n",
    "Python has many ways of reading in data from a netcdf file ... so we thought we would add another way. This is achieved in the `querying.getvar()` function, which is the most commonly used function in the cookbook. This function queries the database to find a specific variable, and loads some or all of that file. We will now take a little while to get to know this function. In it's simplest form, you need just three arguments: expt, variable and database. \n",
    "\n",
    "You can see all the available options using the inbuilt help function, which brings up the function documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cc.querying.getvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may like to note a few things about this function:\n",
    "1. The data is returned as an xarray DataArray, which includes the coordinate and attribute information from the netcdf file (more on xarray later). \n",
    "2. The variable time does not start at zero - and if you don't like it you can introduce an offset to alter the time axis.\n",
    "3. By default, we load the whole dataset, but we can load a subset of the times (see below).\n",
    "4. Other customisable options include setting the variable chunking and incorporating a function to operate on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt = '025deg_jra55v13_ryf8485_gmredi6'\n",
    "variable = 'temp_global_ave'\n",
    "darray = cc.querying.getvar(expt,variable,session)\n",
    "darray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this operation loads the globally averaged potential temperature  from the model output. The time axis runs from 1900 to 2198. For some variables (particularly 3D variables that might use a lot of memory) you may prefer to restrict yourself to a smaller time window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darray = cc.querying.getvar(expt,variable,session,\n",
    "                            start_time='2000-01-01',\n",
    "                            end_time='2050-12-31')\n",
    "darray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that the time boundaries are not exact here. `cc.querying.getvar` loads all files that include any dates within the specified range.  You can use `.sel()` to refine this selection if required (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Exercises\n",
    "OK, this is a tutorial, so now you have to do some work. Your tasks are to:\n",
    "* Find and load SSH from an experiment (an experiment ... perhaps a 1° configuration would be best)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Just load the last 10 files from an experiment (any variable you like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load potential temperature from an experiment (again, 1° would be quickest). Can you chunk the data differently from the default?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How to manipulate and plot variables with xarray\n",
    "We use the python package `xarray` (which is built on `dask`, `pandas`, `matplotlib` and `numpy`) for many of our diagnostics. `xarray` has a a lot of nice features, some of which we will try to demonstrate for you. \n",
    "\n",
    "### 2.1 Plotting\n",
    "`xarray`'s `.plot()` method does its best to figure out what you are trying to plot, and plotting it for you. Let's start by loading a 1-dimensional variable and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt = '025deg_jra55v13_ryf8485_gmredi6'\n",
    "variable = 'temp_global_ave'\n",
    "darray = cc.querying.getvar(expt,variable,session)\n",
    "darray.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that `xarray` has figured out that this data is a timeseries, that the x-axis is representing time and that the y-axis is `temp_global_ave`. You can always modify aspects of your plot if you are unhappy with the default xarray behaviour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darray.plot()\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.title('Globally Averaged Temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `xarray` knows about dimensions, it has plotting routines which can figure out what it should plot. By way of example, let's load a single time slice of `surface_temp` and see how `.plot()` handles it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt = '025deg_jra55v13_ryf8485_gmredi6'\n",
    "variable = 'surface_temp'\n",
    "darray = cc.querying.getvar(expt,variable,session,n=-1)\n",
    "darray.mean('time').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you can customise this plot as you see fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darray = darray - 273.15 # convert from Kelvin to Celsius\n",
    "darray.mean('time').plot.contourf(levels=np.arange(-2,32,2),cmap=cm.cm.thermal)\n",
    "plt.ylabel('latitude')\n",
    "plt.xlabel('longitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Slicing and dicing\n",
    "\n",
    "There are two different ways of subselecting from a DataArray: `isel` and `sel`. The first of these is probably what you are used to -- you specify the value of the index of the array. In the second case you specify the value of the coordinate you want to select. These two methods are demonstrated in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darray = cc.querying.getvar('1deg_jra55v13_iaf_spinup1_B1','pot_rho_2',session)\n",
    "density = darray.isel(time=200).sel(st_ocean=1000,method='nearest')\n",
    "density.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, a 300-year dataset is loaded. We then use `isel` to select the 201st year (timeindex of 200) and use `sel` to select a z level that is about 1000m deep. The `sel` method is very flexible, allowing us to use similar code in differing model resolutions or grids. In addition, both methods allow you to slice a range of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darray = cc.querying.getvar('1deg_jra55v13_iaf_spinup1_B1','v',session)\n",
    "v = darray.isel(time=100).sel(st_ocean=50,method='nearest')\\\n",
    "            .sel(yu_ocean=slice(-50,-20)).sel(xu_ocean=slice(-230,-180)).load()\n",
    "v.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have taken meridional velocity, and sliced out a small region of interest for our plot. Note the `load()` method, which tells `xarray` to do the calculation (otherwise `xarray` aims to defer calculations until the variable is needed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Averaging along dimensions\n",
    "\n",
    "We often perform operations such as averaging on dataarrays. Again, knowledge of the coordinates can be a big help here, as you can instruct the `mean()` method to operate along given coordinates. The case below takes a temporal and zonal average of potential density. (To be precise, it is actually a mean in the i grid direction, which is only zonal outside the tripolar region in the Arctic, i.e. south of 65N in the ACCESS-OM2 models.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darray = cc.querying.getvar('1deg_jra55v13_iaf_spinup1_B1','pot_rho_2',session,n=-10)\n",
    "darray.mean('time').mean('xt_ocean').plot(cmap=cm.cm.haline)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Resampling\n",
    "\n",
    "`xarray` uses `datetime` conventions to allow for operations such as resampling in time. This resampling is simple and powerful. Here is an example of re-plotting the figure from 2.1 with annual averaging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darray = cc.querying.getvar('025deg_jra55v13_iaf_gmredi6','temp_global_ave',session)\n",
    "meandata = darray.resample(time='A').mean(dim='time')\n",
    "meandata.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Exercises\n",
    "\n",
    " * Pick an experiment and plot a map of the temperature of the upper 100m of the ocean for one year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Now, take the same experiment and construct a timeseries of spatially averaged (regional or global) upper 700m temperature, resampled every 3 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. More Advanced Stuff\n",
    "\n",
    "### 3.1 Making a map with cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darray = cc.querying.getvar('025deg_jra55v13_iaf_gmredi6','temp',session,n=-1)\n",
    "temp = darray.mean('time').sel(st_ocean=50,method='nearest') - 273.15\n",
    "plt.figure(figsize=(8,4))\n",
    "ax = plt.axes(projection=ccrs.Robinson())\n",
    "temp.plot.pcolormesh(ax=ax, transform=ccrs.PlateCarree(),x='xt_ocean', y='yt_ocean',cmap=cm.cm.thermal,vmin=-2,vmax=30)\n",
    "#ax.coastlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Distributed computing\n",
    "\n",
    "Many of our scripts use multiple cores for their calculations, usually via the following . It sets up a local cluster on your node for distributed computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dashboard link should allow you to access information on how your work is distributed between the cores on your local cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-20.01]",
   "language": "python",
   "name": "conda-env-analysis3-20.01-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
