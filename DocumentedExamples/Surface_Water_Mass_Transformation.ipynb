{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f60eef0",
   "metadata": {},
   "source": [
    "# Surface Water-Mass Transformation \n",
    "\n",
    "In this notebook, we compute surface water-mass transformation rates (both in the net and partitioned into contributions from heat and salt fluxes) for the southern ocean, south of 60$^\\circ$S. \n",
    "\n",
    "Here we are looking specifically at ACCESS-OM2-01 output (0.1$^\\circ$ resolution, latest spinup), as this configuration has demonstrated considerable success when simulating high latitude dense water formation processes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec251ae0",
   "metadata": {},
   "source": [
    "## 1. Defining surface water-mass transformation\n",
    "\n",
    "The surface water-mass transformation framework described here follows [Newsom *et al* (2016)](https://journals.ametsoc.org/doi/full/10.1175/JCLI-D-15-0513.1) and [Abernathey *et al* (2016)](https://www.nature.com/articles/ngeo2749). Surface water-mass transformation may be defined as the volume flux into a given density class ($\\sigma$) from lighter density classes ($\\sigma'<\\sigma$) due to surface buoyancy forcing. Integrated over a region of the ocean surface, this volume flux can be expressed as,\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\Omega(\\sigma, t) = \\frac{\\partial}{\\partial\\sigma} \\iint_{\\sigma'<\\sigma} \\Big(\\frac{\\partial\\sigma}{\\partial\\theta}\\theta + \\frac{\\partial\\sigma}{\\partial S}S\\Big) \\, \\mathrm{d}x \\, \\mathrm{d}y\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $t$ is time, and the terms in the integrand are the potential temperature ($\\theta$) flux and salinity ($S$) flux components of the surface buoyancy flux. The linearity of this expression means we can extract the relative contributions of heat ($\\Omega_\\text{heat}$) and salinity ($\\Omega_\\text{fw}$) fluxes to surface water-mass transformation, highlighting driving mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7495182",
   "metadata": {},
   "source": [
    "## 2. Requirements\n",
    "\n",
    "**The cosima-cookbook**: The `conda/analysis3-22.10` (or later) module on NCI (or your own up-to-date cookbook installation).\n",
    "\n",
    "**Model diagnostics**: for this example I use some of the long RYF9091 spinup output, if you want to use do surface water-mass transformation analysis on a different experiment you'll need to check you have saved the required diagnostics.\n",
    "\n",
    "**Warning:** if you are using a surface heat flux diagnostic computed online by an ACCESS-OM2 run, make sure that this diagnostic is computed correctly! Some issues were found in the online computation of `net_sfc_heating` (see this [git issue](https://github.com/COSIMA/access-om2/issues/139) from March 2019). In this example we compute net surface heat fluxes offline from component fluxes to avoid these problems - if in doubt use the component fluxes as done here. If you dont have these variables saved and can't re-run... `net_sfc_heating` isn't really so bad for near Antarctic surface water-mass transformation calculations, since transformation rates are strongly dominated by freshwater fluxes, so the errors in heat fluxes confer only a small error to transformation rates.\n",
    "\n",
    "We'll need at least monthly resolution (in `diag_table` language...): `surface_temp`, `surface_salt`, `pme_river`, `sfc_salt_flux_restore`,`sfc_hflux_from_runoff`, `sfc_hflux_coupler`, `sfc_hflux_pme` and `frazil_3d_int_z` (although the latter is not strictly a surface flux, instead frazil heat fluxes are vertically integrated over the column. BUT this variable is highly surface intensified and, in most cases, conceptually relevant to what we want to know from SWMT analysis) plus some basic gridding information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df131a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Computing surface water-mass transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf49a16",
   "metadata": {},
   "source": [
    "First, import some required modules and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39126e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask.array\n",
    "import intake\n",
    "catalog = intake.cat.access_nri\n",
    "from gsw import alpha, SA_from_SP, p_from_z, CT_from_pt, beta, sigma1 \n",
    "# note these gsw numpy functions mean some care is needed to avoid memory issues in very high-res analysis \n",
    "\n",
    "## plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import cmocean.cm as cmo\n",
    "import matplotlib.colors as col\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.path as mpath\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "rc('xtick', labelsize=25) \n",
    "rc('ytick', labelsize=25) \n",
    "rc('axes', labelsize=25) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e31a3",
   "metadata": {},
   "source": [
    "You should also set up a `dask` client - this code uses the vanilla method for doing this. I suggest using Gadi and an entire node (48 cores) for this calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23fb869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-caf8ebda-88ff-11ee-8a15-0000008bfe80</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Direct</td>\n",
       "            <td style=\"text-align: left;\"></td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Scheduler Info</h3></summary>\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-19900ce0-8a83-4a32-99e2-f1128ddc9091</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.6.63.14:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 1\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 48\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 188.56 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: tcp://10.6.63.14:37395</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://10.6.63.14:37395\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 48\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"/proxy/39331/status\" target=\"_blank\">/proxy/39331/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 188.56 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://10.6.63.14:35171\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /scratch/iq82/mp7041/dasktmp/dask-scratch-space/worker-rv8mfao6\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks executing: </strong> \n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in memory: </strong> \n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks ready: </strong> \n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in flight: </strong>\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>CPU usage:</strong> 2.0%\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Last seen: </strong> Just now\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory usage: </strong> 100.29 MiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Spilled bytes: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Read bytes: </strong> 5.26 kiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Write bytes: </strong> 3.78 kiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.6.63.14:8786' processes=1 threads=48, memory=188.56 GiB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## once you've set up a dask-worker, connect to it, click the dashboard link to check worker status\n",
    "from dask.distributed import Client\n",
    "client = Client(\"tcp://10.6.63.14:8786\")\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829509f",
   "metadata": {},
   "source": [
    "I'll be using output from the ACCESS-OM2-01 RYF9091 spinup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb59cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt = '01deg_jra55v13_ryf9091'\n",
    "expt = '1deg_jra55_ryf9091_gadi'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f84d72",
   "metadata": {},
   "source": [
    "#### The function below will compute  surface water-mass transformation rates for the southern ocean, averaged over an integer number of years of monthly resolution output. Below I have flagged some possible modifications you may want/need to employ: \n",
    "\n",
    "- If you are not computing net surface heat fluxes from its components (here we define `net_surface_heating = sfc_hflux_from_runoff + sfc_hflux_coupler + sfc_hflux_pme + frazil_3d_int_z`), the function below will need to be modified to account for this.\n",
    "- If you are not looking at the southern ocean, alter the `yt_ocean` slicing regime.\n",
    "- You may want to use a different density binning array (`isopycnal_bins`)  if the phenomena you're interested in occurs in a shifted density space.\n",
    "- We use $\\sigma_1$ here because we are interested in dense waters that subduct to the Antarctic continental shelf <1000 m depth. You may want to use $\\sigma_0$, $\\sigma_2$ or something else. If so, alter the `gsw` function used, and define a more appropriate `isopycnal_bins` array.\n",
    "- If you're looking at a non-interval number of years, the time averaging scheme will need to be modified.\n",
    "- If you're online computed temperatures (SST) are potential temp (as opposed to conservative temp), use the gsw function `CT_from_pt` before the `sigma1` function as `sigma1` takes conservative temperature input (more info on the TEOS-10 gsw functions [here](http://www.teos-10.org/pubs/gsw/v3_04/html/gsw_contents.html)). This is the case for older ACCESS-OM2-01 runs (e.g. spinup6).\n",
    "- On this `dask` setup and with the memory constraints of the VDI we don't think you would be able to do much more than a 5 year average of 0.1$^\\circ$ data using this function. You are memory-limited by the numpy TEOS-10 gsw functions. If you need to average over more years, you mey have to do the TEOS-10 gsw translations separately and save these prior to computing transformation rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439dc390",
   "metadata": {},
   "source": [
    "When analysing 0.1$^\\circ$ output we tend to compute + save and reload surface water-mass transformation diagnostics in separate steps. In part this is because the computations take a while (~13min for 5 years of data below), but we also find that there's some instability (my workers are always killed) if we instead `return net_transformation, heat_transformation, salt_transformation` and then manipulate these variables straight away (a mystery for another mind). Saving and reloading works fine however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e056d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-23.07/lib/python3.10/site-packages/intake_esm/cat.py:270: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  .applymap(type)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-23.07/lib/python3.10/site-packages/intake_esm/cat.py:270: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  .applymap(type)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-23.07/lib/python3.10/site-packages/intake_esm/cat.py:270: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  .applymap(type)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-23.07/lib/python3.10/site-packages/distributed/client.py:3163: UserWarning: Sending large graph of size 57.80 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;time&#x27; (time: 9360)&gt;\n",
       "array([cftime.DatetimeNoLeap(1900, 2, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1900, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1900, 4, 1, 0, 0, 0, 0, has_year_zero=True), ...,\n",
       "       cftime.DatetimeNoLeap(2679, 11, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2679, 12, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2680, 1, 1, 0, 0, 0, 0, has_year_zero=True)],\n",
       "      dtype=object)\n",
       "Coordinates:\n",
       "  * time     (time) object 1900-02-01 00:00:00 ... 2680-01-01 00:00:00\n",
       "Attributes:\n",
       "    long_name:  model time\n",
       "    bounds:     time_bounds</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'time'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 9360</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-325e0d6b-b176-4db9-bcc8-665e65d0e13d' class='xr-array-in' type='checkbox' checked><label for='section-325e0d6b-b176-4db9-bcc8-665e65d0e13d' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>1900-02-01 00:00:00 1900-03-01 00:00:00 ... 2680-01-01 00:00:00</span></div><div class='xr-array-data'><pre>array([cftime.DatetimeNoLeap(1900, 2, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1900, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1900, 4, 1, 0, 0, 0, 0, has_year_zero=True), ...,\n",
       "       cftime.DatetimeNoLeap(2679, 11, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2679, 12, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2680, 1, 1, 0, 0, 0, 0, has_year_zero=True)],\n",
       "      dtype=object)</pre></div></div></li><li class='xr-section-item'><input id='section-ee1400aa-5bb1-4faa-b91c-b537cd1c097b' class='xr-section-summary-in' type='checkbox'  checked><label for='section-ee1400aa-5bb1-4faa-b91c-b537cd1c097b' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>1900-02-01 00:00:00 ... 2680-01-...</div><input id='attrs-1c0d0428-8ef5-4511-b356-bc635b6e9b68' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-1c0d0428-8ef5-4511-b356-bc635b6e9b68' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7f5b9799-3d66-46e6-8090-69b1c24283ae' class='xr-var-data-in' type='checkbox'><label for='data-7f5b9799-3d66-46e6-8090-69b1c24283ae' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>model time</dd><dt><span>bounds :</span></dt><dd>time_bounds</dd></dl></div><div class='xr-var-data'><pre>array([cftime.DatetimeNoLeap(1900, 2, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1900, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1900, 4, 1, 0, 0, 0, 0, has_year_zero=True), ...,\n",
       "       cftime.DatetimeNoLeap(2679, 11, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2679, 12, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2680, 1, 1, 0, 0, 0, 0, has_year_zero=True)],\n",
       "      dtype=object)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-a6d192b3-1a87-4909-9a5e-25e654ce6d62' class='xr-section-summary-in' type='checkbox'  ><label for='section-a6d192b3-1a87-4909-9a5e-25e654ce6d62' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-f9ac3e6d-2cc3-48cb-a426-df91fd953171' class='xr-index-data-in' type='checkbox'/><label for='index-f9ac3e6d-2cc3-48cb-a426-df91fd953171' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(CFTimeIndex([1900-02-01 00:00:00, 1900-03-01 00:00:00, 1900-04-01 00:00:00,\n",
       "             1900-05-01 00:00:00, 1900-06-01 00:00:00, 1900-07-01 00:00:00,\n",
       "             1900-08-01 00:00:00, 1900-09-01 00:00:00, 1900-10-01 00:00:00,\n",
       "             1900-11-01 00:00:00,\n",
       "             ...\n",
       "             2679-04-01 00:00:00, 2679-05-01 00:00:00, 2679-06-01 00:00:00,\n",
       "             2679-07-01 00:00:00, 2679-08-01 00:00:00, 2679-09-01 00:00:00,\n",
       "             2679-10-01 00:00:00, 2679-11-01 00:00:00, 2679-12-01 00:00:00,\n",
       "             2680-01-01 00:00:00],\n",
       "            dtype=&#x27;object&#x27;, length=9360, calendar=&#x27;noleap&#x27;, freq=&#x27;MS&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-9f06079a-5d2c-4977-8cf9-c06a16b7092a' class='xr-section-summary-in' type='checkbox'  checked><label for='section-9f06079a-5d2c-4977-8cf9-c06a16b7092a' class='xr-section-summary' >Attributes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>model time</dd><dt><span>bounds :</span></dt><dd>time_bounds</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'time' (time: 9360)>\n",
       "array([cftime.DatetimeNoLeap(1900, 2, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1900, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1900, 4, 1, 0, 0, 0, 0, has_year_zero=True), ...,\n",
       "       cftime.DatetimeNoLeap(2679, 11, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2679, 12, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2680, 1, 1, 0, 0, 0, 0, has_year_zero=True)],\n",
       "      dtype=object)\n",
       "Coordinates:\n",
       "  * time     (time) object 1900-02-01 00:00:00 ... 2680-01-01 00:00:00\n",
       "Attributes:\n",
       "    long_name:  model time\n",
       "    bounds:     time_bounds"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_subset = catalog[expt]\n",
    "var_search = cat_subset.search(variable='sst_m', frequency='1mon')\n",
    "darray = var_search.to_dask()\n",
    "darray = darray['sst_m']\n",
    "test = darray\n",
    "test.time ## want to see what the latest years look like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf188fab",
   "metadata": {},
   "source": [
    "Spinup is 200 years; we'll compute surface water-mass transformation averaged over years 186-189 (2086-2089)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5376c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_SWMT(expt, start_time, end_time, outpath, lat_north = -59, n = None):\n",
    "    '''\n",
    "    Computes southern ocean surface water-mass transformation rates (partitioned into transformation from heat \n",
    "    and freshwater) referenced to 1000 db from monthly ACCESS-OM2 output.\n",
    "    Suitable for analysis of high-resolution (0.1 degree) output (the scattered .load()'s allowed this)\n",
    "    \n",
    "    expt - text string indicating the name of the experiment\n",
    "    start_time - text string designating the start month of the analysis ('YYYY-MM', e.g. '1905-01')\n",
    "    end_time - text string indicating the end month of the analysis ('YYY-MM', e.g. '1905-12')\n",
    "    outpath - text string indicating directory where output databases are to be saved (3 xarray databases, can\n",
    "    modify to combine these if memory permits)\n",
    "    lat_north - function computed processes between lat = -90 and lat = lat_north\n",
    "    n - designate if a subset of output files is to be considered (see cc.querying.getvar)\n",
    "    \n",
    "    NOTE: this function assumes you are averaging over an integer number of years (though the start month \n",
    "    need not be january, e.g. can have start_time = '1905-05', end_time = '1907-04' etc), modify if otherwise.\n",
    "    \n",
    "    NOTE: assumes surface_temp and surface_salt variables are in potential temperature (K) and practical\n",
    "    salinity (PSU), simplifications may be made if conservative temperature (C) and absolute salinity (g/kg)\n",
    "    are computed online\n",
    "    \n",
    "    required modules:\n",
    "    xarray as xr\n",
    "    numpy as np\n",
    "    cosima_cookbook as cc\n",
    "    from gsw import alpha, SA_from_SP, p_from_z, CT_from_pt, beta, sigma1 \n",
    "    '''\n",
    "    ## getvar all required variables\n",
    "    cat_subset = catalog[expt]\n",
    "    var_search = cat_subset.search(variable='surface_temp', frequency='1 monthly')\n",
    "    darray = var_search.to_dask()\n",
    "    darray = darray['surface_temp']\n",
    "    SST = darray - 273.15 # SST - conservative temperature in K (sheck this is the case for your run)\n",
    "    cat_subset = catalog[expt]\n",
    "    var_search = cat_subset.search(variable='surface_salt', frequency='1 monthly')\n",
    "    darray = var_search.to_dask()\n",
    "    darray = darray['surface_salt']\n",
    "    SSS_PSU = darray      # SSS - practical salinity (not absolute)\n",
    "    cat_subset = catalog[expt]\n",
    "    var_search = cat_subset.search(variable='pme_river', frequency='1 monthly')\n",
    "    darray = var_search.to_dask()\n",
    "    darray = darray['pme_river']\n",
    "    pme_river = darray       # mass flux of precip - evap + river\n",
    "    # Note that is sfc_salt_flux_ice is not saved, you can use sfc_salt_flux_ice = 0.005 * melt instead\n",
    "    cat_subset = catalog[expt]\n",
    "    var_search = cat_subset.search(variable='sfc_salt_flux_ice', frequency='1 monthly')\n",
    "    darray = var_search.to_dask()\n",
    "    darray = darray['sfc_salt_flux_ice']\n",
    "    sfc_salt_flux_ice = darray         # mass flux of salt from ice formation/melt\n",
    "    cat_subset = catalog[expt]\n",
    "    var_search = cat_subset.search(variable='sfc_salt_flux_restore', frequency='1 monthly')\n",
    "    darray = var_search.to_dask()\n",
    "    darray = darray['sfc_salt_flux_restore']\n",
    "    sfc_salt_flux_restore = darray # mass flux of salt from surface salinity restoring\n",
    "\n",
    "    ## getvar the components of the net surface heat fux instead of the net_surface_heating variable\n",
    "    cat_subset = catalog[expt]\n",
    "    var_search = cat_subset.search(variable='sfc_hflux_from_runoff', frequency='1 monthly')\n",
    "    darray = var_search.to_dask()\n",
    "    darray = darray['sfc_hflux_from_runoff']\n",
    "    sfc_hflux_from_runoff = darray # W/m²\n",
    "    cat_subset = catalog[expt]\n",
    "    var_search = cat_subset.search(variable='sfc_hflux_coupler', frequency='1 monthly')\n",
    "    darray = var_search.to_dask()\n",
    "    darray = darray['sfc_hflux_coupler']\n",
    "    sfc_hflux_coupler = darray         # W/m²\n",
    "    cat_subset = catalog[expt]\n",
    "    var_search = cat_subset.search(variable='sfc_hflux_pme', frequency='1 monthly')\n",
    "    darray = var_search.to_dask()\n",
    "    darray = darray['sfc_hflux_pme']\n",
    "    sfc_hflux_pme = darray                 # W/m²\n",
    "    cat_subset = catalog[expt]\n",
    "    var_search = cat_subset.search(variable='frazil_3d_int_z', frequency='1 monthly')\n",
    "    darray = var_search.to_dask()\n",
    "    darray = darray['frazil_3d_int_z']\n",
    "    frazil_3d_int_z = darray             # W/m²\n",
    "    cat_subset = catalog[expt]\n",
    "    var_search = cat_subset.search(variable='geolon_t')\n",
    "    var_search = var_search.search(path=var_search.df['path'][0])\n",
    "    darray = var_search.to_dask()\n",
    "    darray = darray['geolon_t']\n",
    "    geolon_t = darray\n",
    "    cat_subset = catalog[expt]\n",
    "    var_search = cat_subset.search(variable='geolat_t')\n",
    "    var_search = var_search.search(path=var_search.df['path'][0])\n",
    "    darray = var_search.to_dask()\n",
    "    darray = darray['geolat_t']\n",
    "    geolat_t = darray\n",
    "    \n",
    "    ## slice for time and latitudinal constraints\n",
    "    time_slice = slice(start_time, end_time)\n",
    "    lat_slice = slice(-90, lat_north)\n",
    "    SST = SST.sel(time=time_slice, yt_ocean=lat_slice)\n",
    "    SSS_PSU = SSS_PSU.sel(time=time_slice, yt_ocean=lat_slice)\n",
    "    pme_river = pme_river.sel(time=time_slice, yt_ocean=lat_slice)\n",
    "    sfc_salt_flux_ice = sfc_salt_flux_ice.sel(time=time_slice, yt_ocean=lat_slice)\n",
    "    sfc_salt_flux_restore = sfc_salt_flux_restore.sel(time=time_slice, yt_ocean=lat_slice)\n",
    "    sfc_hflux_from_runoff = sfc_hflux_from_runoff.sel(time=time_slice, yt_ocean=lat_slice)\n",
    "    sfc_hflux_coupler = sfc_hflux_coupler.sel(time=time_slice, yt_ocean=lat_slice)\n",
    "    sfc_hflux_pme = sfc_hflux_pme.sel(time=time_slice, yt_ocean=lat_slice)\n",
    "    frazil_3d_int_z = frazil_3d_int_z.sel(time=time_slice, yt_ocean=lat_slice)\n",
    "    \n",
    "    lon_t = geolon_t.sel(yt_ocean=lat_slice)\n",
    "    lat_t = geolat_t.sel(yt_ocean=lat_slice)\n",
    "    \n",
    "    ## extract coordinate arrays\n",
    "    yt_ocean = SST.yt_ocean.values\n",
    "    xt_ocean = SST.xt_ocean.values\n",
    "    cat_subset = catalog[expt]\n",
    "    var_search = cat_subset.search(variable='st_ocean')\n",
    "    var_search = var_search.search(path=var_search.df['path'][0])\n",
    "    darray = var_search.to_dask()\n",
    "    darray = darray['st_ocean']\n",
    "    st_ocean = darray.load()\n",
    "    time_monthly = SST.time.values\n",
    "    \n",
    "    ## construct an xarray of days per month (check this is relevant to your run), simple modification if non integer number of years analysed\n",
    "    start_month = int(start_time[5:7])\n",
    "    end_month = int(end_time[5:7])\n",
    "    n_years = int(len(SST.time)/12)\n",
    "    months_standard_noleap = np.array([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "    if start_month != 1:\n",
    "        months_offset_noleap = np.append(months_standard_noleap[(start_month-1):],months_standard_noleap[:(start_month-1)])\n",
    "    else:\n",
    "        months_offset_noleap = months_standard_noleap\n",
    "\n",
    "    days_per_month = xr.DataArray(np.tile(months_offset_noleap, n_years), coords = [time_monthly], dims = ['time'], name = 'days per month')\n",
    "\n",
    "    ## compute net surface heat flux from its component terms\n",
    "    net_surface_heating = sfc_hflux_from_runoff+ sfc_hflux_coupler+ sfc_hflux_pme+ frazil_3d_int_z # W/m2\n",
    "    \n",
    "    ## now I use some TEOS-10 gsw functions to compute absolute salinity, then potential density fields\n",
    "    ## these are numpy functions, if you have memory errors this is a good step to check (though I have found\n",
    "    ## this works on the VDI for 0.1 degree data, might be issues for very long time periods)\n",
    "    depth = -st_ocean[0].values # st_ocean value of the uppermost cell\n",
    "    depth_tile = (lat_t*0 + 1) * depth\n",
    "    pressure = xr.DataArray(p_from_z(depth_tile, lat_t), coords = [yt_ocean, xt_ocean], dims = ['yt_ocean', 'xt_ocean'], name = 'pressure', attrs = {'units':'dbar'})\n",
    "    \n",
    "    # convert units to absolute salinity \n",
    "    SSS = xr.DataArray(SA_from_SP(SSS_PSU, pressure, lon_t, lat_t), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'sea surface salinity', attrs = {'units':'Absolute Salinity (g/kg)'})\n",
    "    \n",
    "    ## SST is already saved as conservative temperature in this run, if you are working with an older run with potential \n",
    "    ## temperature saved, conversion will be required (make sure you work with C not K)\n",
    "    # SST = xr.DataArray(CT_from_pt(SSS_AS,SST_PT), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time', 'yt_ocean', 'xt_ocean'], name = 'sea surface temperature', attrs = {'units':'Conservative Temperature (C)'})\n",
    "    # compute potential density referenced to 1000dbar (or referenced otherwise, depending on your purpose)\n",
    "    pot_rho_1 = xr.DataArray(sigma1(SSS, SST), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time', 'yt_ocean', 'xt_ocean'], name = 'potential density ref 1000dbar', attrs = {'units':'kg/m^3 (-1000 kg/m^3)'})\n",
    "    pot_rho_1 = pot_rho_1.load()\n",
    "    \n",
    "    # Compute salt transformation (no density binning)\n",
    "    haline_contraction = xr.DataArray(beta(SSS, SST, pressure), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'saline contraction coefficient (constant conservative temp)', attrs = {'units':'kg/g'})\n",
    "\n",
    "    # Note that the salt fluxes have units of (kg of salt)/m²/s, while β has\n",
    "    # units of kg / (g of salt), so we need to multiply the salt fluxes by 1000,\n",
    "    # the fresh water flux `pme_river` has units of (kg of water)/(m²/s) and needs\n",
    "    # to be multiplied by SSS to convert to (g of salt)/m²/s\n",
    "    # This gives units of (kg of water)/m² for the salt_transformation but it\n",
    "    # will later be divided by time and density and be in m/s:\n",
    "    salt_transformation = haline_contraction * (SSS * pme_river - (sfc_salt_flux_ice + sfc_salt_flux_restore)*1000) * days_per_month #! before was PSU, why?\n",
    "    salt_transformation = salt_transformation.load()\n",
    "\n",
    "    # Compute heat transformation (no density binning)\n",
    "    thermal_expansion = xr.DataArray(alpha(SSS, SST, pressure), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'thermal expansion coefficient (constant conservative temp)', attrs = {'units':'1/K'})\n",
    "    heat_transformation = thermal_expansion * net_surface_heating * days_per_month\n",
    "    heat_transformation = heat_transformation.load()\n",
    "    \n",
    "    # Record the time bounds before summing through time (just to make sure it's consistent with requested years)\n",
    "    time_bounds = str(salt_transformation.coords['time.year'][0].values)+'_'+str(salt_transformation.coords['time.month'][0].values)+'-'+str(salt_transformation.coords['time.year'][-1].values)+'_'+str(salt_transformation.coords['time.month'][-1].values)\n",
    "    \n",
    "    # Next section does a few things. It cycles through isopycnal bins, determines which cells are \n",
    "    # within the given bin for each month, finds the transformation values for those cells for each month, \n",
    "    # and sums these through time. You are left with an array of shape (isopyncal bins * lats * lons) \n",
    "    # where the array associated with a given isopycnal bin is NaN everywhere except where pot_rho_1 \n",
    "    # was within the bin, there it has a time summed transformation value.\n",
    "    \n",
    "    isopycnal_bins = np.arange(31, 33.5, 0.02) ## alter if this density range doesn't capture surface processes in your study region, or if a different density field (not sigma1) is used\n",
    "    \n",
    "    bin_bottoms = isopycnal_bins[:-1]\n",
    "    binned_salt_transformation = xr.DataArray(np.zeros((len(bin_bottoms), len(yt_ocean), len(xt_ocean))), coords = [bin_bottoms, yt_ocean,xt_ocean], dims = ['isopycnal_bins', 'yt_ocean', 'xt_ocean'], name = 'salt transformation in isopycnal bins summed over time')\n",
    "    binned_salt_transformation.chunk({'isopycnal_bins':1})\n",
    "    for i in range(len(isopycnal_bins)-1):\n",
    "        bin_mask = pot_rho_1.where(pot_rho_1 <= isopycnal_bins[i+1]).where(pot_rho_1 > isopycnal_bins[i]) * 0 + 1\n",
    "        masked_transform = (salt_transformation * bin_mask).sum(dim = 'time') \n",
    "        masked_transform = masked_transform.where(masked_transform != 0) \n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_salt_transformation[i, :, :] = masked_transform\n",
    "    print('salt_transformation binning done')\n",
    "    \n",
    "    binned_heat_transformation = xr.DataArray(np.zeros((len(bin_bottoms), len(yt_ocean), len(xt_ocean))), coords = [bin_bottoms, yt_ocean,xt_ocean], dims = ['isopycnal_bins', 'yt_ocean', 'xt_ocean'], name = 'heat transformation in isopycnal bins summed over time')\n",
    "    binned_heat_transformation.chunk({'isopycnal_bins':1})\n",
    "\n",
    "    for i in range(len(isopycnal_bins)-1):\n",
    "        bin_mask = pot_rho_1.where(pot_rho_1 <= isopycnal_bins[i+1]).where(pot_rho_1 > isopycnal_bins[i]) * 0 + 1\n",
    "        masked_transform = (heat_transformation * bin_mask).sum(dim = 'time') \n",
    "        masked_transform = masked_transform.where(masked_transform != 0)\n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_heat_transformation[i, :, :] = masked_transform\n",
    "    print('heat_transformation binning done')\n",
    "    \n",
    "    ndays = days_per_month.sum().values\n",
    "    salt_transformation = binned_salt_transformation/ndays\n",
    "    c_p = 3992.1\n",
    "    heat_transformation = binned_heat_transformation/c_p/ndays\n",
    "    \n",
    "    isopycnal_bin_diff = np.diff(isopycnal_bins)\n",
    "    salt_transformation = salt_transformation / isopycnal_bin_diff[:, np.newaxis, np.newaxis]\n",
    "    heat_transformation = heat_transformation / isopycnal_bin_diff[:, np.newaxis, np.newaxis]\n",
    "    isopycnal_bin_mid = (isopycnal_bins[1:] + isopycnal_bins[:-1])/2\n",
    "    \n",
    "    # this procedure defines fluxes from lighter to denser classes as negative, I want the opposite\n",
    "    salt_transformation = salt_transformation *-1\n",
    "    heat_transformation = heat_transformation *-1\n",
    "    \n",
    "    # Convert the binned (and summed through time) salt and heat transformation DataArrays to Datasets (to save metadata) and save to netCDF\n",
    "    ds = xr.Dataset({'binned_salt_transformation': salt_transformation, 'time_bounds': time_bounds})\n",
    "    ds.to_netcdf(outpath+'/ST_'+time_bounds+'.nc')\n",
    "    ds = xr.Dataset({'binned_heat_transformation': heat_transformation, 'time_bounds': time_bounds})\n",
    "    ds.to_netcdf(outpath+'/HT_'+time_bounds+'.nc')\n",
    "    #############################################################\n",
    "    net_transformation = heat_transformation + salt_transformation\n",
    "    #############################################################\n",
    "    del(heat_transformation, salt_transformation) ## unecessary for lower res or smaller time\n",
    "    # wanted to rename the isopycnal bin (bottom edge) coord with the isopycnal bin midpoints...\n",
    "    net_transformation.coords['isopycnal_bins'] = isopycnal_bin_mid\n",
    "    ds = xr.Dataset({'surface_water_mass_transformation': net_transformation, 'time_bounds': time_bounds})\n",
    "    ds.to_netcdf(outpath+'/SWMT_'+time_bounds+'.nc')\n",
    "    del(net_transformation)\n",
    "    return outpath, time_bounds ## helpful for re-loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae7419a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-23.07/lib/python3.10/site-packages/intake_esm/cat.py:270: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  .applymap(type)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-23.07/lib/python3.10/site-packages/intake_esm/cat.py:270: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  .applymap(type)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected exactly one dataset. Received 0 datasets. Please refine your search or use `.to_dataset_dict()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m, in \u001b[0;36msave_SWMT\u001b[0;34m(expt, start_time, end_time, outpath, lat_north, n)\u001b[0m\n\u001b[1;32m     29\u001b[0m cat_subset \u001b[38;5;241m=\u001b[39m catalog[expt]\n\u001b[1;32m     30\u001b[0m var_search \u001b[38;5;241m=\u001b[39m cat_subset\u001b[38;5;241m.\u001b[39msearch(variable\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurface_temp\u001b[39m\u001b[38;5;124m'\u001b[39m, frequency\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 monthly\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m darray \u001b[38;5;241m=\u001b[39m \u001b[43mvar_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m darray \u001b[38;5;241m=\u001b[39m darray[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurface_temp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     33\u001b[0m SST \u001b[38;5;241m=\u001b[39m darray \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m273.15\u001b[39m \u001b[38;5;66;03m# SST - conservative temperature in K (sheck this is the case for your run)\u001b[39;00m\n",
      "File \u001b[0;32m/g/data/hh5/public/apps/miniconda3/envs/analysis3-23.07/lib/python3.10/site-packages/intake_esm/core.py:802\u001b[0m, in \u001b[0;36mesm_datastore.to_dask\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;124;03mConvert result to an xarray dataset.\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;124;03m:py:class:`~xarray.Dataset`\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# quick check to fail more quickly if there are many results\u001b[39;00m\n\u001b[0;32m--> 802\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    803\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected exactly one dataset. Received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m datasets. Please refine your search or use `.to_dataset_dict()`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    804\u001b[0m     )\n\u001b[1;32m    805\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dataset_dict(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprogressbar\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m})\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# extra check in case kwargs did modify something\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected exactly one dataset. Received 0 datasets. Please refine your search or use `.to_dataset_dict()`."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Make a temporary directory to stash a few files\n",
    "!mkdir -p SWMT_temp\n",
    "outpath = 'SWMT_temp/' # use a path where you have write permission\n",
    "outpath, time_bounds = save_SWMT(expt, '2086-01', '2086-12', outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898570f1",
   "metadata": {},
   "source": [
    "## 4. Reload computed surface water-mass transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "546523ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SWMT(outpath, time_bounds):\n",
    "\n",
    "    net_transformation = xr.open_dataset(outpath + '/SWMT_' + time_bounds + '.nc', chunks={'isopycnal_bins':1})\n",
    "    net_transformation = net_transformation.surface_water_mass_transformation\n",
    "    heat_transformation = xr.open_dataset(outpath + '/HT_' + time_bounds + '.nc', chunks={'isopycnal_bins':1})\n",
    "    heat_transformation = heat_transformation.binned_heat_transformation\n",
    "    salt_transformation = xr.open_dataset(outpath + '/ST_' + time_bounds + '.nc', chunks={'isopycnal_bins':1})\n",
    "    salt_transformation = salt_transformation.binned_salt_transformation\n",
    "\n",
    "    return net_transformation, heat_transformation, salt_transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc353dd",
   "metadata": {},
   "source": [
    "## 5. Plotting options: summed over southern ocean, south of 59S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eb057a",
   "metadata": {},
   "source": [
    "One useful way of visualising the surface water-mass transformation metric is to sum the transformation rates (in density bins) over the analysis region, which here is the entire southern ocean south of 59S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "296ca9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-23.07/lib/python3.10/site-packages/intake_esm/cat.py:270: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  .applymap(type)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-23.07/lib/python3.10/site-packages/intake_esm/cat.py:270: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  .applymap(type)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-23.07/lib/python3.10/site-packages/intake_esm/cat.py:270: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  .applymap(type)\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-23.07/lib/python3.10/site-packages/intake_esm/cat.py:270: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  .applymap(type)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time_bounds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m darray \u001b[38;5;241m=\u001b[39m darray[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marea_t\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m area_t \u001b[38;5;241m=\u001b[39m darray \u001b[38;5;66;03m# needed for the plots I'll provide.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m swmt, heat, salt \u001b[38;5;241m=\u001b[39m get_SWMT(outpath, \u001b[43mtime_bounds\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m## sum over region, convert to Sv\u001b[39;00m\n\u001b[1;32m     10\u001b[0m isopycnal_bin_mid \u001b[38;5;241m=\u001b[39m swmt\u001b[38;5;241m.\u001b[39misopycnal_bins\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time_bounds' is not defined"
     ]
    }
   ],
   "source": [
    "cat_subset = catalog[expt]\n",
    "var_search = cat_subset.search(variable='area_t')\n",
    "var_search = var_search.search(path=var_search.df['path'][0])\n",
    "darray = var_search.to_dask()\n",
    "darray = darray['area_t']\n",
    "area_t = darray # needed for the plots I'll provide.\n",
    "swmt, heat, salt = get_SWMT(outpath, time_bounds)\n",
    "\n",
    "## sum over region, convert to Sv\n",
    "isopycnal_bin_mid = swmt.isopycnal_bins\n",
    "swmt_sum = (swmt * area_t / 1e6).sum(['xt_ocean', 'yt_ocean']).values\n",
    "heat_sum = (heat * area_t / 1e6).sum(['xt_ocean', 'yt_ocean']).values\n",
    "salt_sum = (salt * area_t / 1e6).sum(['xt_ocean', 'yt_ocean']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ccd9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(num=1, figsize = (10, 10))\n",
    "\n",
    "plt.plot(swmt_sum, isopycnal_bin_mid, color = 'k', label='net')\n",
    "plt.plot(heat_sum, isopycnal_bin_mid, color = 'r', label='heat')\n",
    "plt.plot(salt_sum, isopycnal_bin_mid, color = 'b', label='salt')\n",
    "plt.plot([0, 0], [31, 33.2], 'k', linewidth=0.5)\n",
    "plt.ylim((33.2, 31))\n",
    "plt.ylabel(r'$\\sigma_1$ (kg m$^{-3}$)', fontsize = 30)\n",
    "plt.xlabel('Surface water-mass transformation (Sv)', fontsize=30)\n",
    "plt.legend(loc=3, fontsize = 25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115799b",
   "metadata": {},
   "source": [
    "Here the positive peak in the high density classes indicates a rate of subduction due to surface densification processes (predominantly freshwater fluxes associated with sea-ice processes in this case). The negative peak indicates upwelling rates. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c48b284",
   "metadata": {},
   "source": [
    "## 6. Plotting options: Antarctic shelf dense water formation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f7ad7a",
   "metadata": {},
   "source": [
    "You might be interested in dense water formation on the Anarctic continental shelf. Below we've outlined a procedure whereby you can identify the density of subducting waters on the continental shelf, and map the locations where this sudbuction occurs.\n",
    "\n",
    "You will need a way of masking for the continental shelf. You might just use a simple depth criterion, but here I define the shelf region using a mask that selects cells poleward of a continuous approximation of the 1000 m isobath surrounding Antarctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a215d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shelf_mask_isobath(var):\n",
    "    '''\n",
    "    Masks ACCESS-OM2-01 variables by the region polewards of the 1000m isobath as computed using \n",
    "    a script contributed by Adele Morrison.\n",
    "    Only to be used with ACCESS-OM2-0.1 output!\n",
    "    '''\n",
    "    contour_file = np.load('/g/data/ik11/grids/Antarctic_slope_contour_1000m.npz')\n",
    "    \n",
    "    shelf_mask = contour_file['contour_masked_above']\n",
    "    yt_ocean = contour_file['yt_ocean']\n",
    "    xt_ocean = contour_file['xt_ocean']\n",
    "    \n",
    "    # in this file the points along the isobath are given a positive value, the points outside (northwards) \n",
    "    # of the isobath are given a value of -100 and all the points on the continental shelf have a value of 0 \n",
    "    # so we mask for the 0 values \n",
    "    shelf_mask[np.where(shelf_mask!=0)] = np.nan\n",
    "    shelf_mask = shelf_mask+1\n",
    "    shelf_map  = np.nan_to_num(shelf_mask)\n",
    "    shelf_mask = xr.DataArray(shelf_mask, coords = [('yt_ocean', yt_ocean), ('xt_ocean', xt_ocean)])\n",
    "    shelf_map  = xr.DataArray(shelf_map,  coords = [('yt_ocean', yt_ocean), ('xt_ocean', xt_ocean)])\n",
    "    \n",
    "    # then we want to multiply the variable with the mask so we need to account for the shape of the mask. \n",
    "    # The mask uses a northern cutoff of 59S.\n",
    "    masked_var = var.sel(yt_ocean = slice(-90, -59.03)) * shelf_mask\n",
    "\n",
    "    return masked_var, shelf_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03df94a",
   "metadata": {},
   "source": [
    "Below we've plotted the positioning of this isobath boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116ce800",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_subset = catalog[expt]\n",
    "var_search = cat_subset.search(variable='ht')\n",
    "var_search = var_search.search(path=var_search.df['path'][0])\n",
    "darray = var_search.to_dask()\n",
    "darray = darray['ht']\n",
    "ht = darray \n",
    "ht = ht.sel(yt_ocean = slice(-90, -59))\n",
    "\n",
    "land_mask = (ht*0).fillna(1)\n",
    "yt_ocean = ht.yt_ocean.values\n",
    "xt_ocean = ht.xt_ocean.values\n",
    "ht_shelf, shelf_mask = shelf_mask_isobath(ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b565dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(num=1,figsize=(10, 10))\n",
    "\n",
    "ax = plt.subplot(projection=ccrs.SouthPolarStereo())\n",
    "ax.contour(xt_ocean, yt_ocean, land_mask, [0, 1], colors = 'k', alpha = 0.4, transform=ccrs.PlateCarree())\n",
    "ax.contour(xt_ocean, yt_ocean, shelf_mask.values, [0, 1], colors = 'r', transform=ccrs.PlateCarree())\n",
    "ax.set_extent([-180, 180, -90, -59], ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a715e",
   "metadata": {},
   "source": [
    "Now we'll repoduce the previous surface water-mass transformation plot but for the continental shelf region only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba68f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf, shelf_mask = shelf_mask_isobath(swmt)\n",
    "heat_shelf, shelf_mask = shelf_mask_isobath(heat)\n",
    "salt_shelf, shelf_mask = shelf_mask_isobath(salt)\n",
    "area_t_shelf, shelf_mask = shelf_mask_isobath(area_t)\n",
    "swmt_shelf_sum = (swmt_shelf * area_t_shelf / 1e6).sum(['xt_ocean', 'yt_ocean']).values\n",
    "heat_shelf_sum = (heat_shelf * area_t_shelf / 1e6).sum(['xt_ocean', 'yt_ocean']).values\n",
    "salt_shelf_sum = (salt_shelf * area_t_shelf / 1e6).sum(['xt_ocean', 'yt_ocean']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(num = 1, figsize = (10, 10))\n",
    "\n",
    "plt.plot(swmt_shelf_sum, isopycnal_bin_mid, color = 'k', label='net')\n",
    "plt.plot(heat_shelf_sum, isopycnal_bin_mid, color = 'r', label='heat')\n",
    "plt.plot(salt_shelf_sum, isopycnal_bin_mid, color = 'b', label='salt')\n",
    "plt.plot([0, 0], [31, 33.2], 'k', linewidth=0.5)\n",
    "plt.ylim((33.2, 31))\n",
    "plt.ylabel(r'$\\sigma_1$ (kg m$^{-3}$)', fontsize = 30)\n",
    "plt.xlabel('Surface water-mass transformation (Sv)', fontsize = 30)\n",
    "plt.legend(loc=1, fontsize = 25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd7a3e",
   "metadata": {},
   "source": [
    "This shows us that continental shelf surface waters are made denser (almost entirely by sea-ice freshwater fluxes) and subduct away from the surface at a rate of over 8 Sv! Where does this happen? If we map the surface water-mass transformation rate across a chosen density class, we will be able to see where waters are subducting. We know from experience that the dense waters that overflow are best correlated with the transformation on the denser side of the peak, so let's choose $\\sigma_1$ = 32.6 kg/m^3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e241ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_density = 32.6\n",
    "\n",
    "shelf_subduction_plot = swmt_shelf.sel(isopycnal_bins = transformation_density, method='nearest') * 1e5\n",
    "swmt_xt = shelf_subduction_plot.xt_ocean\n",
    "swmt_yt = shelf_subduction_plot.yt_ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig  = plt.figure(1, figsize = (20, 10))\n",
    "gs = gridspec.GridSpec(1,2, width_ratios = [3, 2]) \n",
    "gs.update(wspace = 0.05)\n",
    "\n",
    "ax, ax1 = plt.subplot(gs[0], projection=ccrs.SouthPolarStereo()), plt.subplot(gs[1])\n",
    "\n",
    "ax.contour(xt_ocean, yt_ocean,land_mask, [0, 1],\n",
    "           colors='k', alpha = 0.3, transform = ccrs.PlateCarree() )\n",
    "ax.contour(shelf_mask.xt_ocean, shelf_mask.yt_ocean, shelf_mask, [0, 1],\n",
    "           colors='k', alpha =0.8, transform = ccrs.PlateCarree())\n",
    "\n",
    "norm = col.Normalize(vmin=0, vmax=2.5)\n",
    "\n",
    "plot_swmt = ax.pcolormesh(swmt_xt, swmt_yt, shelf_subduction_plot,\n",
    "                          vmin=0, vmax=2.5, cmap=cmo.matter,transform=ccrs.PlateCarree())\n",
    "\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "center, radius = [0.5, 0.5], 0.5\n",
    "verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "circle = mpath.Path(verts * radius + center)\n",
    "\n",
    "ax.set_extent([-180, 180, -90, -59], ccrs.PlateCarree())\n",
    "\n",
    "cax = fig.add_axes([0.27, 0.03, 0.2, 0.04])\n",
    "cbar = plt.colorbar(plot_swmt, cax=cax, orientation='horizontal', shrink = 0.5, ticks = [0, 0.5, 1, 1.5, 2, 2.5, 3])\n",
    "cbar.set_label(r'Surface water-mass transformation ($\\times 10^{-5}$m s$^{-1}$)', fontsize = 25)\n",
    "\n",
    "ax1.plot(swmt_shelf_sum, isopycnal_bin_mid, color = 'k',label='net')\n",
    "ax1.plot(heat_shelf_sum, isopycnal_bin_mid, color = 'r',label='heat')\n",
    "ax1.plot(salt_shelf_sum, isopycnal_bin_mid, color = 'b',label='salt')\n",
    "ax1.plot([0, 0], [31, 33.2], 'k', linewidth=0.5)\n",
    "ax1.plot([-5, 15], [transformation_density, transformation_density],'k--', linewidth=1)\n",
    "ax1.set_ylim((33.2, 31))\n",
    "ax1.set_xlim((-1.5, 10))\n",
    "ax1.yaxis.set_label_position(\"right\")\n",
    "ax1.yaxis.tick_right()\n",
    "ax1.set_ylabel(r'$\\sigma_1$ (kg m$^{-3}$)', fontsize = 30)\n",
    "ax1.set_xlabel('Surface water-mass transformation (Sv)', fontsize = 30)\n",
    "ax1.legend(loc=1, fontsize = 25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dfc228",
   "metadata": {},
   "source": [
    "### The map in the left panel shows the spatial distribution of surface water-mass transformation across the density class indicated with the dashed line in the right panel. We see the 4 main dense water formation sites around Antarctica, how nice!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-23.07] *",
   "language": "python",
   "name": "conda-env-analysis3-23.07-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
